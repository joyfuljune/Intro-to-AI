<!DOCTYPE html><html lang="en"><head><meta name="description" content="Building AI is a free online course where you&#x27;ll learn about the actual algorithms that make creating AI methods possible. Created by Reaktor and the University of Helsinki."/><meta name="facebook-domain-verification" content="5sy4soors633b01shbmpc6l4nb4rm5"/><meta property="fb:app_id" content=""/><meta property="og:url" content="https://buildingai.elementsofai.com"/><meta property="og:type" content="website"/><meta property="og:title" content="A free online introduction to artificial intelligence for non-experts"/><meta property="og:description" content="Building AI is a free online course where you&#x27;ll learn about the actual algorithms that make creating AI methods possible. Created by Reaktor and the University of Helsinki."/><meta property="og:site_name" content="Elements of AI"/><meta property="og:locale" content="en"/><meta property="og:image" content="https://buildingai.elementsofai.com/OG-IMAGE.png"/><meta property="og:image:secure_url" content="https://buildingai.elementsofai.com/OG-IMAGE.png"/><meta property="og:image:type" content="image/png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="628"/><link rel="preload" href="/pyodide/pyodide.js" as="script"/><script src="/pyodide/pyodide.js"></script><link rel="preload" href="/katex.min.css" as="style"/><link href="/katex.min.css" rel="stylesheet"/><link rel="preload" href="/fonts/GT-Walsheim-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="/fonts/GT-Walsheim-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="/fonts/TiemposTextWeb-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
              new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
              j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
              'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
            })(window,document,'script','dataLayer','GTM-TRS8R6D');</script><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-94af49ae6a477fd8cdc0.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-f0912d88ba6ce3a1caab.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.1092fb9fe53e078c45a4.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.5d496a7ece5c855e79da.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-a17ce805898de2c5f591.js" as="script"/><link rel="preload" href="/_next/static/chunks/85c89d19.0660bb49a9b43dc76719.js" as="script"/><link rel="preload" href="/_next/static/chunks/1bf4c5de.c767f0988a523846e9ff.js" as="script"/><link rel="preload" href="/_next/static/chunks/1114ee98.4bf3e1a1ca62624a5f29.js" as="script"/><link rel="preload" href="/_next/static/chunks/758e262b.bdad50c1a0c468b8e0fe.js" as="script"/><link rel="preload" href="/_next/static/chunks/43f9608f0d2c50fef654bacbb1ba39d104105359.0349ddd1bc5c9a97d4dd.js" as="script"/><link rel="preload" href="/_next/static/chunks/a837b3ba21fd32a2a5784c3bd1d99667024e5b38.b7999c49a3a07326d5c0.js" as="script"/><link rel="preload" href="/_next/static/chunks/1390ee4dffab065ed63ab2216c64196540b39bdc.1127bfe27297a9758032.js" as="script"/><link rel="preload" href="/_next/static/chunks/66e16e6f9b2a463f599e1c15910156399cb51b5b.c8704c236cd1cdc45c27.js" as="script"/><link rel="preload" href="/_next/static/chunks/329a457b8cd4276708afbe7c4a9689c3471fc181.a1d00988fb6b7871dbba.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/Machine-Learning/linear-regression-02d15b2438ed3312d02b.js" as="script"/></head><body><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TRS8R6D"
              height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="__next"></div><script id="__NEXT_DATA__" type="application/json">{"props":{"initialProps":{"pageProps":{"isMobileView":false}},"initialState":{"reducer":{"user":{"user":false,"account":{},"orderStatus":false,"authError":false,"passwordReset":false,"userProgress":{},"features":false},"exercise":{"difficulty":"beginner","editorTheme":false,"correctAnswers":0,"totalExercises":21,"completeExercises":0,"beginnerTrack":0,"intermediateTrack":0,"advancedTrack":0,"exercises":[{"chapter":1,"start":false,"complete":false,"section":2,"data":[{"title":"Exercise 1: Listing pineapple routes","exerciseNumber":1,"beginner":{"id":"1e4af21e-7734-5282-a070-cc464a376e81","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101369","title":"Listing pineapple routes","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101403","title":"Listing pineapple routes","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 2: Pineapple route emissions","exerciseNumber":2,"beginner":{"id":"7252cbff-92b4-5766-9f9c-64558a577de2","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101371","title":"Pineapple route emissions","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101405","title":"Pineapple route emissions","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":1,"start":false,"complete":false,"section":3,"data":[{"title":"Exercise 3: Reach the highest summit","exerciseNumber":3,"beginner":{"id":"e97eaf29-d6d8-5837-9db1-2a1dec51a1a1","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101373","title":"Reach the highest summit","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101407","title":"Reach the highest summit","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 4: Probabilities","exerciseNumber":4,"beginner":{"id":"202618dc-52fd-5977-a942-b814f6d7e35b","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101375","title":"Probabilities","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101409","title":"Probabilities","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 5: Warm-up Temperature","exerciseNumber":5,"beginner":{"id":"97339e0e-6dfc-59ea-8338-b516dee0b893","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false},"intermediate":{"id":"da433f82-b563-5b17-a580-3276ae851e3a","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101411","title":"Warm-up Temperature","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 6: Simulated Annealing","exerciseNumber":6,"beginner":{"id":"3ae47ac2-d2d7-5d3c-8823-dc6e32728340","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101378","title":"Simulated Annealing","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101412","title":"Simulated Annealing","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":2,"start":false,"complete":false,"section":1,"data":[{"title":"Exercise 7: Flip the coin","exerciseNumber":7,"beginner":{"id":"cd59d296-8f49-5ff5-97b3-d9d274a555e0","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101380","title":"Flip the coin","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101414","title":"Flip the coin","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 8: Fishing in the Nordics","exerciseNumber":8,"beginner":{"id":"43123f05-dec1-5c84-909a-e20e8ce30c63","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101382","title":"Fishing in the Nordics","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101416","title":"Fishing in the Nordics","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":2,"start":false,"complete":false,"section":2,"data":[{"title":"Exercise 9: Block or not","exerciseNumber":9,"beginner":{"id":"2537e870-4b2e-57c9-9b90-83f63e58d8c6","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"11b5bfa5-0b82-5e80-be0c-e61c91fb7416","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101418","title":"Block or not","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":2,"start":false,"complete":false,"section":3,"data":[{"title":"Exercise 10: Naive Bayes classifier","exerciseNumber":10,"beginner":{"id":"47395118-16ba-5b98-a829-8aa53baf9e6c","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101385","title":"Naive Bayes Classifier","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101419","title":"Naive Bayes Classifier","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":3,"start":false,"complete":false,"section":1,"data":[{"title":"Exercise 11: Real estate price predictions","exerciseNumber":11,"beginner":{"id":"a1e05151-e63c-53ad-9da5-020c01fc00bd","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101387","title":"Real estate price predictions","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101421","title":"Real estate price predictions","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 12: Least squares","exerciseNumber":12,"beginner":{"id":"b8c3a491-0b81-57d6-a404-553c1009ec86","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101389","title":"Least squares","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101423","title":"Least squares","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 13: Predictions with more data","exerciseNumber":13,"beginner":{"id":"db4b9a3f-6a6d-57a6-bcd1-d247685d55e7","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101391","title":"Predictions with more data","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101425","title":"Predicions with more data","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 14: Training data vs test data","exerciseNumber":14,"beginner":{"id":"f558ab79-f749-5168-add1-d2bf8b141f51","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101393","title":"Training data vs test data","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101427","title":"Training data vs test data","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":3,"start":false,"complete":false,"section":2,"data":[{"title":"Exercise 15: Vector distances","exerciseNumber":15,"beginner":{"id":"6bc4c453-49c9-5966-9f58-8afc8859f235","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"48cee2ae-967f-50f5-9e1e-f2dbe9a8f411","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101429","title":"Vector distances","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 16: Nearest neighbor","exerciseNumber":16,"beginner":{"id":"c0d27ea9-86b7-596a-b1d2-b5e96b7b7b5e","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101396","title":"Nearest neighbor","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101430","title":"Nearest neighbor","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":3,"start":false,"complete":false,"section":3,"data":[{"title":"Exercise 17: Bag of words","exerciseNumber":17,"beginner":{"id":"a9964889-6f37-5696-bf58-431050566a1a","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101398","title":"Bag of words","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101432","title":"Bag of words","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}},{"title":"Exercise 18: TF-IDF","exerciseNumber":18,"beginner":{"id":"d44b7655-af73-5b18-99e7-a2760359c137","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"101400","title":"TF-IDF","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"101434","title":"TF-IDF","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":3,"start":false,"complete":false,"section":4,"data":[{"title":"Exercise 19: Looking out for overfitting","exerciseNumber":19,"beginner":{"id":"b8c62bf4-c4b2-544c-a8e9-4d757d6adb77","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"deb6022a-9c1a-5fbf-a238-f69ecbede584","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"538d4271-4dbf-402f-8e7a-4a9af85d635b","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":4,"start":false,"complete":false,"section":1,"data":[{"title":"Exercise 20: Logistic regression","exerciseNumber":20,"beginner":{"id":"cb006881-955d-5205-925c-2a11e1666fd7","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"dfbdd7e5-1fc1-53a6-9ab4-866daac27b4a","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"105ec65b-2de2-4ec0-8f15-07e51b0f2976","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":4,"start":false,"complete":false,"section":2,"data":[{"title":"Exercise 21: Neural networks","exerciseNumber":21,"beginner":{"id":"48f05b72-10fd-5c83-b5a8-c104c7636376","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"8db327e4-0c2c-54ca-aa7e-23a66e6c4b6c","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"bc1e3314-65eb-4584-bc28-f10f2032a309","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":5,"start":false,"complete":false,"section":2,"data":[{"title":"Your AI idea","exerciseNumber":22,"beginner":{"id":"836dae15-6755-416e-82e8-508afa5b6854","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"a2441f0a-9d66-4282-a24b-4318d242a6f0","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"bcbf760d-a203-46bc-9369-a802e73add15","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false}}]},{"chapter":0,"start":false,"complete":false,"section":1,"data":[{"title":"Exercise 0: Introduction to the Exercises","exerciseNumber":0,"beginner":{"id":"1d9298cf-4c2a-440a-a9af-58b95b9396a2","quiz":{},"quizAnswer":{},"setAnswers":[],"itemAnswers":[],"status":false,"pointAwarded":false,"partialPoints":false},"intermediate":{"id":"119329","title":"Introduction to the Exercises","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false},"advanced":{"id":"119330","title":"Introduction to the Exercises","data":{"code":"","instructionsHeader":"","instructionsFooter":"","answer":"","test":"","dataset":[]},"exerciseBody":"","edit":false,"status":false,"allTestsPassed":false,"pointAwarded":false,"partialPoints":false}}]}]},"code":{"LogisticRegressionAdvanced":"import math\nimport numpy as np\n\nx = np.array([4, 3, 0])\nc1 = np.array([-.5, .1, .08])\nc2 = np.array([-.2, .2, .31])\nc3 = np.array([.5, -.1, 2.53])\n\ndef sigmoid(z):\n    # add your implementation of the sigmoid function here\n    print(0)\n\n# calculate the output of the sigmoid for x with all three coefficients","NeuralNetworksAdvanced":"import numpy as np\n\nw0 = np.array([[ 1.19627687e+01,  2.60163283e-01],\n               [ 4.48832507e-01,  4.00666119e-01],\n                   [-2.75768443e-01,  3.43724167e-01],\n                   [ 2.29138536e+01,  3.91783025e-01],\n                   [-1.22397711e-02, -1.03029800e+00]])\n\nw1 = np.array([[11.5631751 , 11.87043684],\n                   [-0.85735419,  0.27114237]])\n\nw2 = np.array([[11.04122165],\n                   [10.44637262]])\n\nb0 = np.array([-4.21310294, -0.52664488])\nb1 = np.array([-4.84067881, -4.53335139])\nb2 = np.array([-7.52942418])\n\nx = np.array([[111, 13, 12, 1, 161],\n                 [125, 13, 66, 1, 468],\n                 [46, 6, 127, 2, 961],\n                 [80, 9, 80, 2, 816],\n                 [33, 10, 18, 2, 297],\n                 [85, 9, 111, 3, 601],\n                 [24, 10, 105, 2, 1072],\n                 [31, 4, 66, 1, 417],\n                 [56, 3, 60, 1, 36],\n                 [49, 3, 147, 2, 179]])\ny = np.array([335800., 379100., 118950., 247200., 107950., 266550.,  75850.,\n                93300., 170650., 149000.])\n\n\ndef hidden_activation(z):\n    # ReLU activation. fix this!\n        return 0\n\ndef output_activation(z):\n    # identity (linear) activation. fix this!\n        return 0\n\nx_test = [[82, 2, 65, 3, 516]]\nfor item in x_test:\n    h1_in = np.dot(item, w0) + b0 # this calculates the linear combination of inputs and weights\n    h1_out = hidden_activation(h1_in) # apply activation function\n    \n    # fill out the missing parts:\n    # the output of the first hidden layer, h1_out, will need to go through\n    # the second hidden layer with weights w1 and bias b1\n    # and finally to the output layer with weights w2 and bias b2.\n    # remember correct activations: relu in the hidden layers and linear (identity) in the output\n    \n    print(0)","LookingOutForOverfitting":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# create fake data\nx, y = make_moons(\n    n_samples=500,  # the number of observations\n    random_state=42,\n    noise=0.3\n)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n\n# Create a classifier and fit it to our data\nknn = KNeighborsClassifier(n_neighbors=133)\nknn.fit(x_train, y_train)\ntrain_acc = knn.score(x_train, y_train)\n\nprint(\"training accuracy: %f\" % train_acc)\ntest_acc = knn.score(x_test, y_test)\nprint(\"testing accuracy: %f\" % test_acc)","LookingOutForOverfitting_Plot":"from matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\n\n# colors for plotting\ncmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange', 'c', 'darkblue'])\n\n# The code below plots the decision boundaries by predicting the value of each coordinate of the image\nx_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\ny_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n                     np.arange(y_min, y_max, 0.02))\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\nplt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nshow()","LookingOutForOverfittingAdvanced":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# do not edit this\n# create fake data\nx, y = make_moons(\n    n_samples=500,  # the number of observations\n    random_state=42,\n    noise=0.3\n)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n\n# Create a classifier and fit it to our data\nknn = KNeighborsClassifier(n_neighbors=133)\nknn.fit(x_train, y_train)\n\nprint(\"training accuracy: %f\" % 0.0)\nprint(\"testing accuracy: %f\" % 0.0)","LookingOutForOverfittingAdvanced_Plot":"from matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\n\n# colors for plotting\ncmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange', 'c', 'darkblue'])\n\n# The code below plots the decision boundaries by predicting the value of each coordinate of the image\nx_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\ny_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n                     np.arange(y_min, y_max, 0.02))\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\nplt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nshow()","NeuralNetworksIntermediate":"import numpy as np\n\nw0 = np.array([[ 1.19627687e+01,  2.60163283e-01],\n               [ 4.48832507e-01,  4.00666119e-01],\n                              [-2.75768443e-01,  3.43724167e-01],\n                   [ 2.29138536e+01,  3.91783025e-01],\n                   [-1.22397711e-02, -1.03029800e+00]])\n\nw1 = np.array([[11.5631751 , 11.87043684],\n                   [-0.85735419,  0.27114237]])\n\nw2 = np.array([[11.04122165],\n                   [10.44637262]])\n\nb0 = np.array([-4.21310294, -0.52664488])\nb1 = np.array([-4.84067881, -4.53335139])\nb2 = np.array([-7.52942418])\n\nx = np.array([[111, 13, 12, 1, 161],\n                 [125, 13, 66, 1, 468],\n                 [46, 6, 127, 2, 961],\n                 [80, 9, 80, 2, 816],\n                 [33, 10, 18, 2, 297],\n                 [85, 9, 111, 3, 601],\n                 [24, 10, 105, 2, 1072],\n                 [31, 4, 66, 1, 417],\n                 [56, 3, 60, 1, 36],\n                 [49, 3, 147, 2, 179]])\ny = np.array([335800., 379100., 118950., 247200., 107950., 266550.,  75850.,\n                93300., 170650., 149000.])\n\n\ndef hidden_activation(z):\n    # ReLU activation. fix this!\n        return 0\n\ndef output_activation(z):\n    # identity (linear) activation. fix this!\n        return 0\n\nx_test = [[72, 2, 25, 3, 450], [60, 3, 15, 1, 300], [74, 5, 10, 2, 100]]\nfor item in x_test:\n    h1_in = np.dot(item, w0) # this calculates the linear combination of inputs and weights. it is missing the bias term, fix it!\n    h1_out = hidden_activation(h1_in) # apply activation function\n    \n    h2_in = np.dot(h1_out, w1) # the output of the previous layer is the input for this layer. it is missing the bias term, fix it!\n    h2_out = hidden_activation(h2_in)\n    \n    out_in = np.dot(h2_out, w2)\n    out = output_activation(out_in)\n    print(out)","PricePrediction":"import math\nimport numpy as np\n\nx_train = np.array([[25, 2, 50, 1, 500], \n                  [39, 3, 10, 1, 1000],    \n                  [82, 5, 20, 2, 120], \n                  [130, 6, 10, 2, 600]])\ny_train = [127900, 222100,  268000, 460700]\n\nx_test = np.array([[115, 6, 10, 1, 560], [13, 2, 13, 1, 1000]])\n\n\ndef dist(a, b):\n    sum = 0\n    for ai, bi in zip(a, b):\n        sum = sum + (ai - bi)**2\n    return np.sqrt(sum)\n\nn_train = len(x_train) # number of data points in the training set\n\nfor test_item in x_test:\n    d = np.empty(n_train) # d will hold the distances between this test data point and all the training data points\n    for i, train_item in enumerate(x_train):\n        d[i] = dist(test_item, train_item)\n    nearest_index = np.argmin(d) # the nearest neighbour will be in y_train[nearest]\n    print(y_train[nearest_index])","ProximityOfNeighbors":"# input values for one mökkis: size, size of sauna, distance to water, number of indoor bathrooms, \n# proximity of neighbours\n\nx = [66, 5, 15, 2, 500]\nc = [3000, 200 , -50, 5000, 100]     # coefficient values\n\nprediction = c[0]*x[0] + c[1]*x[1] + c[2]*x[2] + c[3]*x[3] + c[4]*x[4]\n\nprint(prediction)","LeastSquares":"import numpy as np\n\n\nx = np.array([\n             [25, 2, 50, 1, 500], \n             [39, 3, 10, 1, 1000], \n             [13, 2, 13, 1, 1000], \n             [82, 5, 20, 2, 120], \n             [130, 6, 10, 2, 600]\n            ])   \ny = np.array([127900, 222100, 143750, 268000, 460700])\n\nc = np.linalg.lstsq(x, y)[0]\nprint(c)\nprint(x @ c)","Ex0_Code_1_intermediate":"# you can define your own functions\ndef greet(name):\n    print(\"Welcome \" + name + \"!\")\n\n# go ahead and enter your own name in variable 'name' below to get a warm welcome from us.\n\ndef main():\n    name = \"Emma\"\n    greet(name)\n\nmain()","Ex0_Test_1_intermediate":"import contextlib\nimport unittest\nimport io\nimport unittest.mock\nfrom unittest import TextTestRunner\n\nclass MainTest(unittest.TestCase):\n\n    def test_answer(self):\n        capturedOutput = io.StringIO()\n        sys.stdout = capturedOutput\n        main()\n        sys.stdout = sys.__stdout__\n\n        output = capturedOutput.getvalue().strip()\n\n        self.assertEqual(output, \"Welcome to Building AI!\")\n\n\ntest_suite = unittest.TestLoader().loadTestsFromTestCase(MainTest)\nwith io.StringIO() as buf:\n    # run the tests\n    with contextlib.redirect_stdout(buf):\n        TextTestRunner(stream=buf).run(test_suite)\n    # process (in this case: print) the results\n    printTest(buf.getvalue())","Ex0_Code_2_intermediate":"import numpy as np\nimport matplotlib.pyplot as plt\n# generate a 30-by-50 array of random numbers\nx = np.random.rand(30, 50)\n# the following code that will plot the numbers as colors would normally\n# be hidden from you, so again, you won't have to worry about it.\n# try clicking the 'Plot' button to see the outcome.\nplt.figure(figsize=(3,5))\nplt.axis('off')\nplt.imshow(x, cmap='Set3')","Ex0_Test_2_intermediate":"printTest(\"No tests for this exercise\")","Ex0_Plot_2_intermediate":"show()","plot_exercise3_advanced":"import matplotlib.pyplot as plt                                                    \t \ndef plot_exercise3_advanced(h):\n\n    x0, x = main(h)\n    plt.plot(range(100), h)\n    plt.plot([x0], [h[x0]], 'gs')\n    plt.plot([x], [h[x]], 'r\u003e')\n\n    plt.plot([x], [h[x]], 'b^')\n    show()\n\nplot_exercise3_advanced(h)","plot_exercise3_intermediate":"import matplotlib.pyplot as plt  \ndef plot_exercise3_intermediate(h):\n\n    x0, x = main(h)\n    plt.plot(range(100), h)\n    plt.plot([x0], [h[x0]], 'gs')\n    plt.plot([x], [h[x]], 'r\u003e')\n\n    plt.plot([x], [h[x]], 'b^')\n    show()\n\nplot_exercise3_intermediate(h)","plot_exercise6_intermediate":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom matplotlib.patches import Polygon\n\ndef plot_exercise6_intermediate():\n    xx = np.array(list(range(n)))\n    yy = np.array(h)\n    plt.figure(figsize=(10,2))\n    plt.gca().set_ylim(0, 1.2)\n    plt.gca().set_xlim(0, n)\n    plotlim = plt.gca().get_xlim() + plt.gca().get_ylim()  \n    cmap = mpl.cm.Blues(np.linspace(.2,.6,100))\n    cmap = mpl.colors.ListedColormap(cmap[10:,:-1])\n    plt.imshow([[0,0],[1,1]], cmap=cmap, interpolation='bicubic', extent=plotlim, zorder=-200)  \n    plt.grid(False)\n    plt.fill_between(xx, 0, yy, color='rosybrown', zorder=-150)\n    gradient_fill(xx, yy, 'white', plt.gca(), color='None')\n    plt.plot([x0], [h[x0]], color='k', marker='s', markersize=10, zorder=50)\n    plt.plot([x], [h[x]], color='r', marker='*', markersize=15, zorder=51) \n\n    show()\n\nplot_exercise6_intermediate()","plot_exercise6_advanced":"import matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nplt.xlim(0, N-1)\nplt.ylim(0, N-1)\nplt.imshow(h, cmap=cm.gist_earth)\nplt.scatter([peak_y], [peak_x], color='red', marker='+', s=100)\nfor j in range(tracks):\n    c = cm.tab20(j/tracks)     # use different colors for different tracks  \n    plt.scatter([y[j]], [x[j]], color=c, s=20)\nshow()","plot_exercise16_advanced":"from matplotlib import pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.collections import LineCollection\n\ndef plot():\n    # plot the chart\n    fig = plt.figure()\n    ax = plt.gca()\n    ax.set_axis_off()\n    fig.set_facecolor('#EBE9EF')\n    cm = ListedColormap(['#5EC798', '#46479D'])\n    plt.scatter(X_train[:,0], X_train[:,1], c=y_train, marker='o',\n                cmap=cm, s=160, vmin=0, vmax=1)\n    plt.scatter(X_test[:,0], X_test[:,1], c=y_predict, marker='*', \n                cmap=cm, s=220, vmin=0, vmax=1)\n    lc = LineCollection(lines, zorder=-1)\n    ax.add_collection(lc)\n\n    show()\n\nplot()","plot_exercise16_intermediate":"from matplotlib import pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.collections import LineCollection\n\ndef plot():\n    # plot the chart\n    fig = plt.figure()\n    ax = plt.gca()\n    ax.set_axis_off()\n    fig.set_facecolor('#EBE9EF')\n    cm = ListedColormap(['#5EC798', '#46479D'])\n    plt.scatter(X_train[:,0], X_train[:,1], c=y_train, marker='o',\n                cmap=cm, s=160, vmin=0, vmax=1)\n    plt.scatter(X_test[:,0], X_test[:,1], c=y_predict, marker='*', \n                cmap=cm, s=220, vmin=0, vmax=1)\n    lc = LineCollection(lines, zorder=-1)\n    ax.add_collection(lc)\n\n    show()\n    \nplot()","print":"import sys\nimport io\nimport contextlib\n\noutput = []\nfigureOutput = []\ntestOutput = []\n\ndef print(*objects, sep='',  end=''):\n    def _print(object, end):\n        global output\n        lines = str(object).split('\\n')\n        if len(lines) \u003e 1:\n            output.extend(lines[:-1])\n            output.append(lines[-1] + end)\n        else:\n            output.append(str(object) + end)\n\n       # output += list(str(object) + end)\n    if len(objects) == 0:\n        _print(\"\", end)\n        return\n    for object in objects[:-1]:\n        _print(object, sep)\n    _print(objects[-1], end)\n\n    if end == '':\n        end = '\\n'\n    sys.stdout.write(str(objects[-1]) + end)\n\ndef printTest(*objects, sep='',  end=''):\n    def _printTest(object, end):\n        global testOutput\n        testOutput.append(str(object) + end)\n\n    if len(objects) == 0:\n        _printTest(\"\", end)\n        return\n    for object in objects[:-1]:\n        _printTest(object, sep)\n    _printTest(objects[-1], end)\n\n    if end == '':\n        end = '\\n'\n    sys.stdout.write(str(objects[-1]) + end)","show":"import io, base64\ndef show():\n    buf = io.BytesIO()\n    plt.savefig(buf, format='png')\n    buf.seek(0)\n    figureOutput.append('data:image/png;base64,' + base64.b64encode(buf.read()).decode('UTF-8'))","gradient_fill":"def gradient_fill(x, y, fill_color=None, ax=None, **kwargs):\n    if ax is None:\n        ax = plt.gca()\n\n    line, = ax.plot(x, y, **kwargs)\n    if fill_color is None:\n        fill_color = line.get_color()\n\n    zorder = line.get_zorder()\n    alpha = line.get_alpha()\n    alpha = 1.0 if alpha is None else alpha\n\n    z = np.empty((100, 1, 4), dtype=float)\n    rgb = mcolors.colorConverter.to_rgb(fill_color)\n    z[:,:,:3] = rgb\n    z[:,:,-1] = np.linspace(0, alpha, 100)[:,None]\n\n    xmin, xmax, ymin, ymax = x.min(), x.max(), y.min(), y.max()\n    im = ax.imshow(z, aspect='auto', extent=[xmin, xmax, ymin, ymax],\n                   origin='lower', zorder=zorder)\n\n    xy = np.column_stack([x, y])\n    xy = np.vstack([[xmin, ymin], xy, [xmax, ymin], [xmin, ymin]])\n    clip_path = Polygon(xy, facecolor='none', edgecolor='none', closed=True, zorder=-100)\n    ax.add_patch(clip_path)\n    im.set_clip_path(clip_path)\n\n    return line, im","defaults":{"LogisticRegressionAdvanced":"import math\nimport numpy as np\n\nx = np.array([4, 3, 0])\nc1 = np.array([-.5, .1, .08])\nc2 = np.array([-.2, .2, .31])\nc3 = np.array([.5, -.1, 2.53])\n\ndef sigmoid(z):\n    # add your implementation of the sigmoid function here\n    print(0)\n\n# calculate the output of the sigmoid for x with all three coefficients","NeuralNetworksAdvanced":"import numpy as np\n\nw0 = np.array([[ 1.19627687e+01,  2.60163283e-01],\n               [ 4.48832507e-01,  4.00666119e-01],\n                   [-2.75768443e-01,  3.43724167e-01],\n                   [ 2.29138536e+01,  3.91783025e-01],\n                   [-1.22397711e-02, -1.03029800e+00]])\n\nw1 = np.array([[11.5631751 , 11.87043684],\n                   [-0.85735419,  0.27114237]])\n\nw2 = np.array([[11.04122165],\n                   [10.44637262]])\n\nb0 = np.array([-4.21310294, -0.52664488])\nb1 = np.array([-4.84067881, -4.53335139])\nb2 = np.array([-7.52942418])\n\nx = np.array([[111, 13, 12, 1, 161],\n                 [125, 13, 66, 1, 468],\n                 [46, 6, 127, 2, 961],\n                 [80, 9, 80, 2, 816],\n                 [33, 10, 18, 2, 297],\n                 [85, 9, 111, 3, 601],\n                 [24, 10, 105, 2, 1072],\n                 [31, 4, 66, 1, 417],\n                 [56, 3, 60, 1, 36],\n                 [49, 3, 147, 2, 179]])\ny = np.array([335800., 379100., 118950., 247200., 107950., 266550.,  75850.,\n                93300., 170650., 149000.])\n\n\ndef hidden_activation(z):\n    # ReLU activation. fix this!\n        return 0\n\ndef output_activation(z):\n    # identity (linear) activation. fix this!\n        return 0\n\nx_test = [[82, 2, 65, 3, 516]]\nfor item in x_test:\n    h1_in = np.dot(item, w0) + b0 # this calculates the linear combination of inputs and weights\n    h1_out = hidden_activation(h1_in) # apply activation function\n    \n    # fill out the missing parts:\n    # the output of the first hidden layer, h1_out, will need to go through\n    # the second hidden layer with weights w1 and bias b1\n    # and finally to the output layer with weights w2 and bias b2.\n    # remember correct activations: relu in the hidden layers and linear (identity) in the output\n    \n    print(0)","LookingOutForOverfitting":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# create fake data\nx, y = make_moons(\n    n_samples=500,  # the number of observations\n    random_state=42,\n    noise=0.3\n)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n\n# Create a classifier and fit it to our data\nknn = KNeighborsClassifier(n_neighbors=133)\nknn.fit(x_train, y_train)\ntrain_acc = knn.score(x_train, y_train)\n\nprint(\"training accuracy: %f\" % train_acc)\ntest_acc = knn.score(x_test, y_test)\nprint(\"testing accuracy: %f\" % test_acc)","LookingOutForOverfitting_Plot":"from matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\n\n# colors for plotting\ncmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange', 'c', 'darkblue'])\n\n# The code below plots the decision boundaries by predicting the value of each coordinate of the image\nx_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\ny_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n                     np.arange(y_min, y_max, 0.02))\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\nplt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nshow()","LookingOutForOverfittingAdvanced":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# do not edit this\n# create fake data\nx, y = make_moons(\n    n_samples=500,  # the number of observations\n    random_state=42,\n    noise=0.3\n)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n\n# Create a classifier and fit it to our data\nknn = KNeighborsClassifier(n_neighbors=133)\nknn.fit(x_train, y_train)\n\nprint(\"training accuracy: %f\" % 0.0)\nprint(\"testing accuracy: %f\" % 0.0)","LookingOutForOverfittingAdvanced_Plot":"from matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\n\n# colors for plotting\ncmap_light = ListedColormap(['orange', 'cyan', 'cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange', 'c', 'darkblue'])\n\n# The code below plots the decision boundaries by predicting the value of each coordinate of the image\nx_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\ny_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n                     np.arange(y_min, y_max, 0.02))\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.figure()\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\nplt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nshow()","NeuralNetworksIntermediate":"import numpy as np\n\nw0 = np.array([[ 1.19627687e+01,  2.60163283e-01],\n               [ 4.48832507e-01,  4.00666119e-01],\n                              [-2.75768443e-01,  3.43724167e-01],\n                   [ 2.29138536e+01,  3.91783025e-01],\n                   [-1.22397711e-02, -1.03029800e+00]])\n\nw1 = np.array([[11.5631751 , 11.87043684],\n                   [-0.85735419,  0.27114237]])\n\nw2 = np.array([[11.04122165],\n                   [10.44637262]])\n\nb0 = np.array([-4.21310294, -0.52664488])\nb1 = np.array([-4.84067881, -4.53335139])\nb2 = np.array([-7.52942418])\n\nx = np.array([[111, 13, 12, 1, 161],\n                 [125, 13, 66, 1, 468],\n                 [46, 6, 127, 2, 961],\n                 [80, 9, 80, 2, 816],\n                 [33, 10, 18, 2, 297],\n                 [85, 9, 111, 3, 601],\n                 [24, 10, 105, 2, 1072],\n                 [31, 4, 66, 1, 417],\n                 [56, 3, 60, 1, 36],\n                 [49, 3, 147, 2, 179]])\ny = np.array([335800., 379100., 118950., 247200., 107950., 266550.,  75850.,\n                93300., 170650., 149000.])\n\n\ndef hidden_activation(z):\n    # ReLU activation. fix this!\n        return 0\n\ndef output_activation(z):\n    # identity (linear) activation. fix this!\n        return 0\n\nx_test = [[72, 2, 25, 3, 450], [60, 3, 15, 1, 300], [74, 5, 10, 2, 100]]\nfor item in x_test:\n    h1_in = np.dot(item, w0) # this calculates the linear combination of inputs and weights. it is missing the bias term, fix it!\n    h1_out = hidden_activation(h1_in) # apply activation function\n    \n    h2_in = np.dot(h1_out, w1) # the output of the previous layer is the input for this layer. it is missing the bias term, fix it!\n    h2_out = hidden_activation(h2_in)\n    \n    out_in = np.dot(h2_out, w2)\n    out = output_activation(out_in)\n    print(out)","PricePrediction":"import math\nimport numpy as np\n\nx_train = np.array([[25, 2, 50, 1, 500], \n                  [39, 3, 10, 1, 1000],    \n                  [82, 5, 20, 2, 120], \n                  [130, 6, 10, 2, 600]])\ny_train = [127900, 222100,  268000, 460700]\n\nx_test = np.array([[115, 6, 10, 1, 560], [13, 2, 13, 1, 1000]])\n\n\ndef dist(a, b):\n    sum = 0\n    for ai, bi in zip(a, b):\n        sum = sum + (ai - bi)**2\n    return np.sqrt(sum)\n\nn_train = len(x_train) # number of data points in the training set\n\nfor test_item in x_test:\n    d = np.empty(n_train) # d will hold the distances between this test data point and all the training data points\n    for i, train_item in enumerate(x_train):\n        d[i] = dist(test_item, train_item)\n    nearest_index = np.argmin(d) # the nearest neighbour will be in y_train[nearest]\n    print(y_train[nearest_index])","ProximityOfNeighbors":"# input values for one mökkis: size, size of sauna, distance to water, number of indoor bathrooms, \n# proximity of neighbours\n\nx = [66, 5, 15, 2, 500]\nc = [3000, 200 , -50, 5000, 100]     # coefficient values\n\nprediction = c[0]*x[0] + c[1]*x[1] + c[2]*x[2] + c[3]*x[3] + c[4]*x[4]\n\nprint(prediction)","LeastSquares":"import numpy as np\n\n\nx = np.array([\n             [25, 2, 50, 1, 500], \n             [39, 3, 10, 1, 1000], \n             [13, 2, 13, 1, 1000], \n             [82, 5, 20, 2, 120], \n             [130, 6, 10, 2, 600]\n            ])   \ny = np.array([127900, 222100, 143750, 268000, 460700])\n\nc = np.linalg.lstsq(x, y)[0]\nprint(c)\nprint(x @ c)","Ex0_Code_1_intermediate":"# you can define your own functions\ndef greet(name):\n    print(\"Welcome \" + name + \"!\")\n\n# go ahead and enter your own name in variable 'name' below to get a warm welcome from us.\n\ndef main():\n    name = \"Emma\"\n    greet(name)\n\nmain()","Ex0_Test_1_intermediate":"import contextlib\nimport unittest\nimport io\nimport unittest.mock\nfrom unittest import TextTestRunner\n\nclass MainTest(unittest.TestCase):\n\n    def test_answer(self):\n        capturedOutput = io.StringIO()\n        sys.stdout = capturedOutput\n        main()\n        sys.stdout = sys.__stdout__\n\n        output = capturedOutput.getvalue().strip()\n\n        self.assertEqual(output, \"Welcome to Building AI!\")\n\n\ntest_suite = unittest.TestLoader().loadTestsFromTestCase(MainTest)\nwith io.StringIO() as buf:\n    # run the tests\n    with contextlib.redirect_stdout(buf):\n        TextTestRunner(stream=buf).run(test_suite)\n    # process (in this case: print) the results\n    printTest(buf.getvalue())","Ex0_Code_2_intermediate":"import numpy as np\nimport matplotlib.pyplot as plt\n# generate a 30-by-50 array of random numbers\nx = np.random.rand(30, 50)\n# the following code that will plot the numbers as colors would normally\n# be hidden from you, so again, you won't have to worry about it.\n# try clicking the 'Plot' button to see the outcome.\nplt.figure(figsize=(3,5))\nplt.axis('off')\nplt.imshow(x, cmap='Set3')","Ex0_Test_2_intermediate":"printTest(\"No tests for this exercise\")","Ex0_Plot_2_intermediate":"show()","plot_exercise3_advanced":"import matplotlib.pyplot as plt                                                    \t \ndef plot_exercise3_advanced(h):\n\n    x0, x = main(h)\n    plt.plot(range(100), h)\n    plt.plot([x0], [h[x0]], 'gs')\n    plt.plot([x], [h[x]], 'r\u003e')\n\n    plt.plot([x], [h[x]], 'b^')\n    show()\n\nplot_exercise3_advanced(h)","plot_exercise3_intermediate":"import matplotlib.pyplot as plt  \ndef plot_exercise3_intermediate(h):\n\n    x0, x = main(h)\n    plt.plot(range(100), h)\n    plt.plot([x0], [h[x0]], 'gs')\n    plt.plot([x], [h[x]], 'r\u003e')\n\n    plt.plot([x], [h[x]], 'b^')\n    show()\n\nplot_exercise3_intermediate(h)","plot_exercise6_intermediate":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom matplotlib.patches import Polygon\n\ndef plot_exercise6_intermediate():\n    xx = np.array(list(range(n)))\n    yy = np.array(h)\n    plt.figure(figsize=(10,2))\n    plt.gca().set_ylim(0, 1.2)\n    plt.gca().set_xlim(0, n)\n    plotlim = plt.gca().get_xlim() + plt.gca().get_ylim()  \n    cmap = mpl.cm.Blues(np.linspace(.2,.6,100))\n    cmap = mpl.colors.ListedColormap(cmap[10:,:-1])\n    plt.imshow([[0,0],[1,1]], cmap=cmap, interpolation='bicubic', extent=plotlim, zorder=-200)  \n    plt.grid(False)\n    plt.fill_between(xx, 0, yy, color='rosybrown', zorder=-150)\n    gradient_fill(xx, yy, 'white', plt.gca(), color='None')\n    plt.plot([x0], [h[x0]], color='k', marker='s', markersize=10, zorder=50)\n    plt.plot([x], [h[x]], color='r', marker='*', markersize=15, zorder=51) \n\n    show()\n\nplot_exercise6_intermediate()","plot_exercise6_advanced":"import matplotlib.pyplot as plt\nfrom matplotlib import cm\n\nplt.xlim(0, N-1)\nplt.ylim(0, N-1)\nplt.imshow(h, cmap=cm.gist_earth)\nplt.scatter([peak_y], [peak_x], color='red', marker='+', s=100)\nfor j in range(tracks):\n    c = cm.tab20(j/tracks)     # use different colors for different tracks  \n    plt.scatter([y[j]], [x[j]], color=c, s=20)\nshow()","plot_exercise16_advanced":"from matplotlib import pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.collections import LineCollection\n\ndef plot():\n    # plot the chart\n    fig = plt.figure()\n    ax = plt.gca()\n    ax.set_axis_off()\n    fig.set_facecolor('#EBE9EF')\n    cm = ListedColormap(['#5EC798', '#46479D'])\n    plt.scatter(X_train[:,0], X_train[:,1], c=y_train, marker='o',\n                cmap=cm, s=160, vmin=0, vmax=1)\n    plt.scatter(X_test[:,0], X_test[:,1], c=y_predict, marker='*', \n                cmap=cm, s=220, vmin=0, vmax=1)\n    lc = LineCollection(lines, zorder=-1)\n    ax.add_collection(lc)\n\n    show()\n\nplot()","plot_exercise16_intermediate":"from matplotlib import pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.collections import LineCollection\n\ndef plot():\n    # plot the chart\n    fig = plt.figure()\n    ax = plt.gca()\n    ax.set_axis_off()\n    fig.set_facecolor('#EBE9EF')\n    cm = ListedColormap(['#5EC798', '#46479D'])\n    plt.scatter(X_train[:,0], X_train[:,1], c=y_train, marker='o',\n                cmap=cm, s=160, vmin=0, vmax=1)\n    plt.scatter(X_test[:,0], X_test[:,1], c=y_predict, marker='*', \n                cmap=cm, s=220, vmin=0, vmax=1)\n    lc = LineCollection(lines, zorder=-1)\n    ax.add_collection(lc)\n\n    show()\n    \nplot()","print":"import sys\nimport io\nimport contextlib\n\noutput = []\nfigureOutput = []\ntestOutput = []\n\ndef print(*objects, sep='',  end=''):\n    def _print(object, end):\n        global output\n        lines = str(object).split('\\n')\n        if len(lines) \u003e 1:\n            output.extend(lines[:-1])\n            output.append(lines[-1] + end)\n        else:\n            output.append(str(object) + end)\n\n       # output += list(str(object) + end)\n    if len(objects) == 0:\n        _print(\"\", end)\n        return\n    for object in objects[:-1]:\n        _print(object, sep)\n    _print(objects[-1], end)\n\n    if end == '':\n        end = '\\n'\n    sys.stdout.write(str(objects[-1]) + end)\n\ndef printTest(*objects, sep='',  end=''):\n    def _printTest(object, end):\n        global testOutput\n        testOutput.append(str(object) + end)\n\n    if len(objects) == 0:\n        _printTest(\"\", end)\n        return\n    for object in objects[:-1]:\n        _printTest(object, sep)\n    _printTest(objects[-1], end)\n\n    if end == '':\n        end = '\\n'\n    sys.stdout.write(str(objects[-1]) + end)","show":"import io, base64\ndef show():\n    buf = io.BytesIO()\n    plt.savefig(buf, format='png')\n    buf.seek(0)\n    figureOutput.append('data:image/png;base64,' + base64.b64encode(buf.read()).decode('UTF-8'))","gradient_fill":"def gradient_fill(x, y, fill_color=None, ax=None, **kwargs):\n    if ax is None:\n        ax = plt.gca()\n\n    line, = ax.plot(x, y, **kwargs)\n    if fill_color is None:\n        fill_color = line.get_color()\n\n    zorder = line.get_zorder()\n    alpha = line.get_alpha()\n    alpha = 1.0 if alpha is None else alpha\n\n    z = np.empty((100, 1, 4), dtype=float)\n    rgb = mcolors.colorConverter.to_rgb(fill_color)\n    z[:,:,:3] = rgb\n    z[:,:,-1] = np.linspace(0, alpha, 100)[:,None]\n\n    xmin, xmax, ymin, ymax = x.min(), x.max(), y.min(), y.max()\n    im = ax.imshow(z, aspect='auto', extent=[xmin, xmax, ymin, ymax],\n                   origin='lower', zorder=zorder)\n\n    xy = np.column_stack([x, y])\n    xy = np.vstack([[xmin, ymin], xy, [xmax, ymin], [xmin, ymin]])\n    clip_path = Polygon(xy, facecolor='none', edgecolor='none', closed=True, zorder=-100)\n    ax.add_patch(clip_path)\n    im.set_clip_path(clip_path)\n\n    return line, im"}}},"_persist":{"version":-1,"rehydrated":false}}},"page":"/Machine-Learning/linear-regression","query":{},"buildId":"eABXGm5-RTvRTI6Bh_Yzb","isFallback":false,"customServer":true,"gip":true,"appGip":true,"head":[["meta",{"charSet":"utf-8"}],["meta",{"name":"viewport","content":"width=device-width"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-fbb3ef9f7698ceb36885.js"></script><script src="/_next/static/chunks/main-94af49ae6a477fd8cdc0.js" async=""></script><script src="/_next/static/chunks/webpack-f0912d88ba6ce3a1caab.js" async=""></script><script src="/_next/static/chunks/framework.1092fb9fe53e078c45a4.js" async=""></script><script src="/_next/static/chunks/commons.5d496a7ece5c855e79da.js" async=""></script><script src="/_next/static/chunks/pages/_app-a17ce805898de2c5f591.js" async=""></script><script src="/_next/static/chunks/85c89d19.0660bb49a9b43dc76719.js" async=""></script><script src="/_next/static/chunks/1bf4c5de.c767f0988a523846e9ff.js" async=""></script><script src="/_next/static/chunks/1114ee98.4bf3e1a1ca62624a5f29.js" async=""></script><script src="/_next/static/chunks/758e262b.bdad50c1a0c468b8e0fe.js" async=""></script><script src="/_next/static/chunks/43f9608f0d2c50fef654bacbb1ba39d104105359.0349ddd1bc5c9a97d4dd.js" async=""></script><script src="/_next/static/chunks/a837b3ba21fd32a2a5784c3bd1d99667024e5b38.b7999c49a3a07326d5c0.js" async=""></script><script src="/_next/static/chunks/1390ee4dffab065ed63ab2216c64196540b39bdc.1127bfe27297a9758032.js" async=""></script><script src="/_next/static/chunks/66e16e6f9b2a463f599e1c15910156399cb51b5b.c8704c236cd1cdc45c27.js" async=""></script><script src="/_next/static/chunks/329a457b8cd4276708afbe7c4a9689c3471fc181.a1d00988fb6b7871dbba.js" async=""></script><script src="/_next/static/chunks/pages/Machine-Learning/linear-regression-02d15b2438ed3312d02b.js" async=""></script><script src="/_next/static/eABXGm5-RTvRTI6Bh_Yzb/_buildManifest.js" async=""></script><script src="/_next/static/eABXGm5-RTvRTI6Bh_Yzb/_ssgManifest.js" async=""></script></body></html>