{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe09e0f",
   "metadata": {},
   "source": [
    "姓名：小宝  \n",
    "学号：20202020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628acb5f",
   "metadata": {},
   "source": [
    "<h1 align='center'> 神经网络 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15243577",
   "metadata": {},
   "source": [
    "<h6> 目录 </h6>\n",
    "\n",
    "- [逻辑递归](#LR)\n",
    "    - [练习1. 逻辑递归](#lr_ex)\n",
    "- [从逻辑递归到神经网络](#nn)\n",
    "    - [练习2. 神经网络的激活函数](#nn_ex)\n",
    "-[项目：是否录取？](#admission)\n",
    "    - [练习3. 高校录取预测](#ex3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fd5f0",
   "metadata": {},
   "source": [
    "<h2> 逻辑递归 <a id = 'LR'> </a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabb87e",
   "metadata": {},
   "source": [
    "我们的下一个主题，神经网络，往往比本课程的其他主题加起来更吸引人的兴趣。也许这是因为人们希望了解自己的思想，而我们的思想——就目前所知——是由我们大脑中的神经处理产 生的。 然而，我们将从一个连接传统回归建模和神经网络的想法开始，即逻辑回归。 这将有助于我们探索机器学习，而不至于迷失方向。\n",
    "\n",
    "此外， 逻辑回归 实际上是一种非常有用和实用的技术。 出发点是熟悉的线性回归模型： $b + w_1 × x_1 + ...+ w_n × x_n$， 这代表了一个模型，其中系数和 输入的数量为n，所以最后一项是一些$w_n × x_n$，而三个点$...$是一个简短的符号，取代了第一项 和最后一项之间的所有项。回顾一下，第一项， b，被称为截距参数。 然而， 线性回归和逻辑回归之间的区别在于上述线性函数计算完成后会发生什么。在线性回归 中，我们已经完成了， 线性函数就是输出。在逻辑回归中，我们利用线性函数的结果，并对 其应用一个特殊的非线性函数，称为`sigmoid`函数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56ff7b",
   "metadata": {},
   "source": [
    "![step_sig](step_sig.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c629a7",
   "metadata": {},
   "source": [
    "上图总结了线性回归和逻辑回归之间的区别。两者都是从计算输入的线性函数开始的，用 希腊字母∑（大写sigma）表示，通常用来表示加法。在逻辑回归中， 结果再通过`sigmoid`函数。 `sigmoid`函数的数学公式（见下文）可能看起来有点吓人，但它的目的很简单：它将任何数字转换为0和1之间的值。 \n",
    "\n",
    "`sigmoid`函数的输入越大， 输出越接近1.0， 输入越小， 输出越接近0.0。例如， 0.0的值被转换为0.5，而10.0的值被转换为0.9999546，离1.0只差一点点。同样地， 值 -10被转换为0.0000454，也就是比0.0大一丁点。 由于输出值是一个介于0和1之间的数字，它可以被解释为一个概率。 这很有用，因为我们 将使用逻辑回归来预测某事发生的概率，而不是使用一个数值（如以欧元为单位的价格或以 公斤为单位的碳排放数量）。如果我们在医学诊断中使用逻辑回归，模型的输出可以是例如某种疾 病的概率。或者如果我们想知道一个笑脸是否快乐，模型的输出可以是它快乐的概率。当正好有 两种选择时（高兴或不高兴，有病或无病），第二种结果的概率当然是一减去第一种结果 的概率。 然后， 该模型可以用来将不同的项目分为两类， 这样我们就可以读取模型的输出并将其解释为 其中一类的概率。我们通常将这两个类标记为0和1，并让模型的输出成为类1的概率。 定义`sigmoid`函数的数学公式如下。\n",
    "$$\\sigma(z) = \\frac{1}{1+exp(-z)}$$\n",
    "\n",
    "指数函数$exp(z) = e^{-z}$, (e升至-z的幂)，其中e是所谓的欧拉数，大约等于$2.718$ 。它可以通过数学模块中的Python函数`exp`来计算。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595cd32",
   "metadata": {},
   "source": [
    "你可能想知道逻辑回归模型是否只适用于二分类问题，也就是0或1。 好消息是： 不是这样的。 有一个简单的,可以进行多酚类的函数被称为`softmax`。 我们不会在这里讨论它，但它同样在神经网络中被大量使用。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a99de8",
   "metadata": {},
   "source": [
    "现在我们了解了逻辑回归模型，它只是在线性回归模型的尾部添加了`sigmoid`函数，现在是讨论如何从数据中学习这种模型的时候了。\n",
    "\n",
    "就像在线性回归中，学习过程涉及到权重或系数的调整，以便模型尽可能地适合训练数据。在标准线性回归的情况下，优化标准是误差的平方，最小二乘法很快就能给我们解决方案。然而，在逻辑回归中，输出是概率，观察到的反应是二进制的 \"是/否 \"标签，优化标准是平方误差以外的东西。\n",
    "\n",
    "逻辑回归中的实际优化标准被称为对数损失。它是通过使用逻辑回归模型来评估观察到的标签的概率来计算的：如果观察到的标签是类 \n",
    "1，概率就直接从`sigmoid`输出中得到；如果观察到的标签是类0，概率从$1-sigmoid$输出得到。一组特定数据的对数损失是这些概率的负对数之和。我们不会讨论计算对数损失的细节，也不会讨论最小化对数损失的算法：我们可以跳过这些，直接进入有趣的部分，即使用现成的工具，只需要几个Python命令，工作就完成了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c5f3c",
   "metadata": {},
   "source": [
    "<h4> 练习1 逻辑回归 <a id='lr_ex'> </a></h4>\n",
    "<h5> 练习1.1 </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af1399a",
   "metadata": {},
   "source": [
    "这里我们有一个（虚构的）关于学习Python的时间与一年内获得加薪的机会的数据图表。如果你的朋友花了70个小时学习Python，她在一年内获得加薪的机会是多少？\n",
    "<img src=\"lr_ex.png\" alt= “” width=\"500\" height=\"200\">\n",
    "\n",
    "- 小于25%\n",
    "- 50%\n",
    "- 最少80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97279820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你的答案是"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c6ec5",
   "metadata": {},
   "source": [
    "就像线性回归一样，逻辑回归也是一种简单但广泛使用的技术。它已被成功用于医学（评估各种不良健康状况的风险，如心脏病、癌症或COVID-19）、社会科学（对影响投票决定或犯罪的因素进行建模）、市场营销（谁会点击在线广告）以及其他无数领域的应用。\n",
    "\n",
    "重要的是要认识到，决定一个应用是否会成功的最重要因素往往不是你选择使用哪种机器学习方法，而是你如何使用它：训练数据的数量和质量，数据的预处理和表示方式，结果的解释和应用方式，等等。\n",
    "\n",
    "然而，在某些时候，方法本身可能成为限制性因素。其中一个限制就是模型的线性度。线性回归和逻辑回归都是所谓的线性模型，Naive Bayes也是如此。\n",
    "\n",
    "一个线性方法不适合的问题的例子是根据用户的年龄来预测用户点击尿布或其他育儿产品广告的机会。有小宝宝的父母往往是20多岁到30多岁之间的人。一个逻辑回归模型，点击广告的概率随着年龄的增加或减少而持续增加或减少，无法为年轻用户输出低概率，为20-40岁之间的用户输出高概率，为年长用户输出低概率。\n",
    "\n",
    "线性限制实际上可以通过以适当的方式预处理数据来规避，例如，将年龄编码为 \"分类 \"变量，这意味着我们为每个年龄组包括一个指标变量（例如，0-9岁，10-19岁，20-29岁，以此类推）。然而，这将导致模型中更多的参数和更高的过拟合风险，除非我们有足够的数据。\n",
    "\n",
    "找到正确的方法来编码数据可能是非常乏味的 \"手工 \"工作。幸运的是，还有一个解决方案。如果我们怀疑数据中可能存在一些非线性模式，如上面的尿布例子，我们也可以应用非线性方法，如最近的邻居方法。另一个常见的例子是本章的主题--神经网络。\n",
    "\n",
    "没有一个明确的方法可以事先告诉我们哪种机器学习方法，以及哪种表示数据的方式会产生最好的结果。在实践中，机器学习是一门务实的艺术，涉及到大量的实验，最好的方法往往只能通过试验和错误找到。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e639af0",
   "metadata": {},
   "source": [
    "<h5> 练习1.2 </h5>\n",
    "\n",
    "其中哪些是正确地实现了`sigmoid`函数？请选择所有正确的实现方式。\n",
    "\n",
    "- 选项A\n",
    "\n",
    "```python\n",
    "def sigmoid(x):\n",
    "\treturn 1 / 1+math.exp(-x)\n",
    "```\n",
    "- 选项B\n",
    "\n",
    "```python\n",
    "def sigmoid(x):\n",
    "\treturn 1 / (1 + math.exp(x))\n",
    "```\n",
    "- 选项C\n",
    "\n",
    "```python\n",
    "def sigmoid(x):\n",
    "\treturn 1 / (1 + math.exp(-x))\n",
    "```\n",
    "- 选项D\n",
    "\n",
    "```python\n",
    "def sigmoid(x):\n",
    "\tx2 = -1.0*x\n",
    "\ta = math.exp(x2)\n",
    "\tnominator = 1\n",
    "\tdenominator = 1 + a\n",
    "\treturn nominator / denominator\n",
    "```\n",
    "- 选项E\n",
    "\n",
    "```python\n",
    "def sigmoid(x):\n",
    "\treturn 1 / (1 + 2.71**(-x))\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfeb5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你的答案是"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396d728",
   "metadata": {},
   "source": [
    "<details><summary><h6>点击查看答案</h6></summary>3、4、3.848、3.848、sigmoid、0.98</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3131626",
   "metadata": {},
   "source": [
    "<details><summary><h6>点击查看答案</h6></summary>c3=1.2235162625848273最大</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cacf9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个数据是《这只小猪》的词袋表示法\n",
    "data = [[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1],\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
    "        [1, 1, 1, 0, 1, 3, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]]\n",
    "def distance(row1, row2):\n",
    "    # 修复这个函数，使其返回在行1和行2中出现的每个词的差异之和\n",
    "    # 你可以假设row1和row2是长度相等的列表，包含数字值\n",
    "    return 0\n",
    "def all_pairs(data):\n",
    "    # 这将调用数据中所有两行组合的距离函数\n",
    "    # 你不需要改变这个\n",
    "    dist = [[distance(sent1, sent2) for sent1 in data] for sent2 in data]\n",
    "    print(dist)\n",
    "    \n",
    "all_pairs(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00119dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = [1,2]\n",
    "b = [3,4]\n",
    "sum(np.subtract(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ed574",
   "metadata": {},
   "source": [
    "<h5> 练习1.3 <a id='1.3'></a></h5> \n",
    "\n",
    "给你一组三个输入值，你也有多组备选的三个系数。使用线性公式结合逻辑激活函数计算预测的输出值。\n",
    "\n",
    "对所有的备选系数集进行计算。哪一组系数产生了最高的sigmoid输出？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ba88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([4, 3, 0])\n",
    "c1 = np.array([-.5, .1, .08])\n",
    "c2 = np.array([-.2, .2, .31])\n",
    "c3 = np.array([.5, -.1, 2.53])\n",
    "\n",
    "def sigmoid(z):\n",
    "    # 在这里添加你对sigmoid函数的实现\n",
    "    print(0)\n",
    "\n",
    "# 用所有三个系数计算x的sigmoid输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c8f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你的答案是，选择c1,c2,c3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c15457",
   "metadata": {},
   "source": [
    "<details><summary><h6>点击查看答案</h6></summary>c3=1.2235162625848273最大</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca9caf",
   "metadata": {},
   "source": [
    "就像线性回归一样，逻辑回归也是一种简单但广泛使用的技术。它已被成功用于医学（评估各种不良健康状况的风险，如心脏病、癌症或COVID-19）、社会科学（对影响投票决定或犯罪的因素进行建模）、市场营销（谁会点击在线广告）以及其他无数领域的应用。\n",
    "\n",
    "重要的是要认识到，决定一个应用是否会成功的最重要因素往往不是你选择使用哪种机器学习方法，而是你如何使用它：训练数据的数量和质量，数据的预处理和表示方式，结果的解释和应用方式，等等。\n",
    "\n",
    "然而，在某些时候，方法本身可能成为限制性因素。其中一个限制就是模型的线性度。线性回归和逻辑回归都是所谓的线性模型，Naive Bayes也是如此。\n",
    "\n",
    "一个线性方法不适合的问题的例子是根据用户的年龄来预测用户点击尿布或其他育儿产品广告的机会。有小宝宝的父母往往是20多岁到30多岁之间的人。一个逻辑回归模型，点击广告的概率随着年龄的增加或减少而持续增加或减少，无法为年轻用户输出低概率，为20-40岁之间的用户输出高概率，为年长用户输出低概率。\n",
    "\n",
    "线性限制实际上可以通过以适当的方式预处理数据来规避，例如，将年龄编码为 \"分类 \"变量，这意味着我们为每个年龄组包括一个指标变量（例如，0-9岁，10-19岁，20-29岁，以此类推）。然而，这将导致模型中更多的参数和更高的过拟合风险，除非我们有足够的数据。\n",
    "\n",
    "找到正确的方法来编码数据可能是非常乏味的 \"手工 \"工作。幸运的是，还有一个解决方案。如果我们怀疑数据中可能存在一些非线性模式，如上面的尿布例子，我们也可以应用非线性方法，如最近的邻居方法。另一个常见的例子是本章的主题--神经网络。\n",
    "\n",
    "没有一个明确的方法可以事先告诉我们哪种机器学习方法，以及哪种表示数据的方式会产生最好的结果。在实践中，机器学习是一门务实的艺术，涉及到大量的实验，最好的方法往往只能通过试验和错误找到。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1fc2bc",
   "metadata": {},
   "source": [
    "<h2> 从逻辑递归到神经网络<a id='nn'></a> </h2>\n",
    "\n",
    "既然我们已经研究了逻辑回归，那么神经网络的基本思想实际上只有一小步之遥。我们保留了线性函数与非线性函数（如sigmoid函数）相结合的想法。神经网络对此的补充是，我们将多个这样的模型连接在一起，得到一个网络。\n",
    "\n",
    "当谈及神经网络时，我们使用的术语略有不同。我们不说系数，而说权重。模型的非线性部分，在逻辑回归的情况下是sigmoid函数，被称为激活函数。一个这样的模型被称为神经元。神经元通过让一个神经元的输出成为另一个神经元的输入而相互连接。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1eabb",
   "metadata": {},
   "source": [
    "![neural network](crop_NN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0edeab",
   "metadata": {},
   "source": [
    "让我们开始分解这个图。在这种情况下，我们的神经网络是一个有2个输入节点的网络，用$x_1, x_2$表示，再加上一个截距$b_1$。中间是一个有3个节点的隐藏层$z_{11}, z_{12}, z_{13}$ 和另一个截距$b_2$,同时有一个节点的输出层$z_21$\n",
    "\n",
    "输入层和隐藏层是连接在一起的，因此隐藏层中的每个节点的行为与逻辑回归模型并无二致，该模型的输入来自于输入节点。同样，隐藏层中的节点与输出节点的连接方式也很相同：这次隐藏层中的节点为输出节点提供输入。\n",
    "\n",
    "输入层就是它听起来的样子：它是你的输入数据。这里唯一的新东西是用节点的方式来思考，一个节点对应于输入中的一个元素\n",
    "\n",
    "这些节点的行为与逻辑回归模型非常相似。在每个节点内，我们计算节点输入的线性组合--记得在输出节点的情况下，这些是由隐藏层的节点提供的——并应用类似sigmoid函数的东西来确定实际输出。如上所述，我们把在后一阶段应用的函数称为激活函数。这个术语是直接从神经科学中借来的，神经元在被接收到的刺激激活时，通过向其他神经元发送电脉冲进行交流。\n",
    "\n",
    "在输入层和隐藏层中，我们各有一个偏置节点。偏置节点的目的在功能上与线性回归中的截距项相同：它可以将来自某一层的输入转移到另一层的某个常量值。例如在上面的网络中，$b_2$将最终输出层得到的输入转移到一个由输出节点的系数权重决定的恒定值上。偏置节点不是神经网络的强制性特征，但通常对模型性能有帮助。\n",
    "\n",
    "这一切有什么意义呢？如果我们退一步看神经网络，它就是一个盒子，我们在里面插入输入，输出就出来了。把它看成是一个有输入和输出的函数，它的作用与任何回归或分类模型相同。由于单个神经元并不比逻辑回归模型更复杂，这到底有什么用？\n",
    "\n",
    "魔术发生在网络内部的神经元使用非线性激活函数的地方。事实上，如果我们只使用线性激活，可以证明整个网络只是一个线性回归模型。但如果我们使用非线性激活，如sigmoid函数或称为整流线性单元的东西——为了听起来专业，就说ReLu模型变得比线性模型强大得多。事实上，只要网络中有足够的节点，我们就能学会完美地适应几乎任何数据。表达这一点的技术方法是说，神经网络是 \"通用函数近似器\"。\n",
    "\n",
    "即使是一个有少量神经元的相对简单的模型，也能学习到对线性模型（如线性回归、逻辑回归或Naive Bayes）来说太多的东西。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c7ff0",
   "metadata": {},
   "source": [
    "词袋方法的一个问题是我们基本上对任何单词都给予同等重视：单词“a”出现十次与单词“great”出现十次一样重要。 但是，例如，如果我们考虑文本情感（分析某人的感受），“a”和“great”显然并不同等重要。\n",
    "\n",
    "我们可以应用一种流行且有效的解决方案来改进简单的词袋表示，其首字母缩写为 tf-idf。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48296c88",
   "metadata": {},
   "source": [
    "<h4> 练习2 神经网络 <a id='nn_ex'></a> </h4>\n",
    "<h5> 练习2.1 </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24587b55",
   "metadata": {},
   "source": [
    "根据下图，回答问题\n",
    "<img src=\"ex_nn.png\" alt= “” width=\"500\" height=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43d1ae",
   "metadata": {},
   "source": [
    "- 考虑一下上图中的神经网络。它有多少个输入节点？\n",
    "    - 3\n",
    "    - 4\n",
    "    - 5\n",
    "    - 8\n",
    "    \n",
    "+ 隐藏的节点呢？\n",
    "    - 3\n",
    "    - 4\n",
    "    - 5\n",
    "    - 8\n",
    "\n",
    "+ 让我们把重点放在隐藏节点上。在对节点a_1施加激活函数之前，节点$a_1$中的线性组合的值是多少？\n",
    "    - 8.6\n",
    "    - 3.848\n",
    "    - 0.002\n",
    "    - 以上都不是\n",
    "\n",
    "+ 如果我们选择使用线性激活函数，这个节点的输出会是什么？\n",
    "    - 8.6\n",
    "    - 3.848\n",
    "    - 0.002\n",
    "    - 以上都不是\n",
    "\n",
    "+ 如果你的最终任务是根据一个东西的高度、重量和长度来预测它是一只狗还是一只猫，你会选择什么作为输出层的激活函数？\n",
    "    - 恒等函数，因为我们要识别一个东西\n",
    "    - sigmoid，因为输出将是它是其中之一的概率\n",
    "    - 两者都不是\n",
    "    - 两者都可以\n",
    "\n",
    "+ 如果我们选择使用sigmoid激活函数，这个节点的输出将是什么？\n",
    "    - ~0.98\n",
    "    - ~1\n",
    "    - ~0.5\n",
    "    - 这些都不是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你的答案是"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f01e1c",
   "metadata": {},
   "source": [
    "<details><summary><h6>点击查看答案</h6></summary>3、4、3.848、3.848、sigmoid、0.98</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c49039",
   "metadata": {},
   "source": [
    "<h5> 练习2.2 </h5>\n",
    "\n",
    "我们用较大的小木屋价格数据集训练了一个简单的神经网络。该网络根据小木屋的属性来预测小木屋的价格。该网络包括一个有五个节点的输入层，一个有两个节点的隐藏层，一个有两个节点的第二隐藏层，最后是一个有一个节点的输出层。此外，每个隐藏层和输出层都有一个偏置节点。\n",
    "\n",
    "下面的程序使用这个训练过的网络的权重来执行所谓的神经网络的前向传递。前向传递是通过神经网络运行输入变量以获得输出，在这种情况下，是给定属性的小屋的价格。\n",
    "\n",
    "不过，这个程序是不完整的。下面的版本中没有使用偏置节点，隐藏层和输出层的激活函数也没有被正确定义。\n",
    "\n",
    "修改程序以使用偏置节点，并对隐藏节点使用ReLU激活函数，对输出节点使用线性（恒等）激活。**ReLU激活函数要么返回函数的输入值，要么返回0，以最大者为准，而线性激活只是将输入作为输出返回**。做完这些后，得到一个小木屋价格的预测，该预测由以下特征向量$[74, 5, 10, 2, 100]$描述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f29f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w0 = np.array([ [ 1.19627687e+01, 2.60163283e-01],\n",
    "               [ 4.48832507e-01, 4.00666119e-01],\n",
    "                              [-2.75768443e-01, 3.43724167e-01],\n",
    "                   [2.29138536e+01, 3.91783025e-01]\n",
    "                   [-1.22397711e-02, -1.03029800e+00]])\n",
    "\n",
    "w1 = np.array([[11.5631751 , 11.87043684],\n",
    "                   [-0.85735419, 0.27114237]])\n",
    "\n",
    "w2 = np.array([[11.04122165],\n",
    "                   [10.44637262]])\n",
    "\n",
    "b0 = np.array([-4.21310294, -0.52664488])\n",
    "b1 = np.array([-4.84067881, -4.53335139])\n",
    "b2 = np.array([-7.52942418])\n",
    "\n",
    "x = np.array([[111, 13, 12, 1, 161],\n",
    "                 [125, 13, 66, 1, 468],\n",
    "                 [46, 6, 127, 2, 961],\n",
    "                 [80, 9, 80, 2, 816],\n",
    "                 [33, 10, 18, 2, 297],\n",
    "                 [85, 9, 111, 3, 601],\n",
    "                 [24, 10, 105, 2, 1072],\n",
    "                 [31, 4, 66, 1, 417],\n",
    "                 [56, 3, 60, 1, 36],\n",
    "                 [49, 3, 147, 2, 179]])\n",
    "y = np.array([335800., 379100., 118950., 247200., 107950., 266550., 75850,\n",
    "                93300., 170650., 149000.])\n",
    "\n",
    "\n",
    "def hidden_activation(z):\n",
    "    # ReLU激活\n",
    "    return 0\n",
    "\n",
    "def output_activation(z):\n",
    "    # 恒等（线性）激活\n",
    "    return 0\n",
    "\n",
    "x_test = [[72, 2, 25, 3, 450], [60, 3, 15, 1, 300], [74, 5, 10, 2, 100]]\n",
    "for item in x_test:\n",
    "    h1_in = np.dot(item, w0) # 这是计算输入和权重的线性组合。它缺少偏置项，请修复它\n",
    "    h1_out = hidden_activation(h1_in) # 应用激活函数\n",
    "    \n",
    "    h2_in = np.dot(h1_out, w1) # 前一层的输出是这一层的输入。\n",
    "    h2_out = hidden_activation(h2_in)\n",
    "    \n",
    "    out_in = np.dot(h2_out, w2)\n",
    "    out = output_activation(out_in)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c0191",
   "metadata": {},
   "source": [
    "- 神经网络预测有关小屋的价格是多少？\n",
    "    - 大约233,000元\n",
    "    - 大约230,000元\n",
    "    - 大约184,000元\n",
    "\n",
    "- 这是一个什么类型的机器学习问题？\n",
    "    - 强化学习\n",
    "    - 有监督的学习\n",
    "    - 无监督学习\n",
    "\n",
    "- 我们怎样才能确保我们的神经网络不会对数据过度拟合？\n",
    "    - 使用交叉验证法\n",
    "    - 将全部机舱数据作为训练集，并将其中一小部分作为测试集。\n",
    "    - 神经网络总是会过度拟合，因为对于这样的线性问题来说，有太多的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf66c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你的答案是"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297b617",
   "metadata": {},
   "source": [
    "<details><summary><h6>点击查看答案</h6></summary>233，000、监督学习、交叉验证</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca644546",
   "metadata": {},
   "source": [
    "<h5> 练习2.3 </h5>\n",
    "\n",
    "根据上一题，修改该程序，以进行完整的前向传递并打印出价格预测。要做到这一点，请写出剩余的前向传递操作，并对隐藏节点使用ReLU激活函数，对输出节点使用线性（身份）激活。ReLU激活函数要么返回函数的输入值，要么返回0，以最大者为准，而线性激活只是将输入作为输出返回。做完这些后，得到一个小木屋价格的预测，该预测由以下特征向量描述$[82, 2, 65, 3, 516]$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6199f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w0 = np.array([ [ 1.19627687e+01, 2.60163283e-01],\n",
    "               [ 4.48832507e-01, 4.00666119e-01],\n",
    "                   [-2.75768443e-01, 3.43724167e-01],\n",
    "                   [2.29138536e+01, 3.91783025e-01]。\n",
    "                   [-1.22397711e-02, -1.03029800e+00]])\n",
    "\n",
    "w1 = np.array([[11.5631751 , 11.87043684],\n",
    "                   [-0.85735419, 0.27114237]])\n",
    "\n",
    "w2 = np.array([[11.04122165],\n",
    "                   [10.44637262]])\n",
    "\n",
    "b0 = np.array([-4.21310294, -0.52664488])\n",
    "b1 = np.array([-4.84067881, -4.53335139])\n",
    "b2 = np.array([-7.52942418])\n",
    "\n",
    "x = np.array([[111, 13, 12, 1, 161],\n",
    "                 [125, 13, 66, 1, 468],\n",
    "                 [46, 6, 127, 2, 961],\n",
    "                 [80, 9, 80, 2, 816],\n",
    "                 [33, 10, 18, 2, 297],\n",
    "                 [85, 9, 111, 3, 601],\n",
    "                 [24, 10, 105, 2, 1072],\n",
    "                 [31, 4, 66, 1, 417],\n",
    "                 [56, 3, 60, 1, 36],\n",
    "                 [49, 3, 147, 2, 179]])\n",
    "y = np.array([335800., 379100., 118950., 247200., 107950., 266550., 75850。\n",
    "                93300., 170650., 149000.])\n",
    "\n",
    "\n",
    "def hidden_activation(z):\n",
    "    # ReLU激活。解决这个问题\n",
    "    return 0\n",
    "\n",
    "def output_activation(z):\n",
    "    # 相同的（线性）激活。\n",
    "    return 0\n",
    "\n",
    "x_test = [[82, 2, 65, 3, 516]]\n",
    "for item in x_test:\n",
    "    h1_in = np.dot(item, w0) + b0 # 这计算了输入和权重的线性组合\n",
    "    h1_out = hidden_activation(h1_in) # 应用激活函数\n",
    "    \n",
    "    # 补齐缺失的部分。\n",
    "    # 第一个隐藏层的输出，h1_out，将需要经过\n",
    "    # 第二个隐藏层的权重w1和偏置b1\n",
    "    # 最后到输出层，权重为w2，偏置为b2。\n",
    "    # 记住正确的激活：隐藏层中的relu和输出层中的线性（identity）。\n",
    "    \n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffedd09",
   "metadata": {},
   "source": [
    "- 神经网络预测输入矢量$[82, 2, 65, 3, 516]$所描述的小屋的价格是多少？\n",
    "    - 大约295,400元\n",
    "    - 大约300,120元\n",
    "    - 大约257,100元\n",
    "    - 大约231,650元\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ccde7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你的答案是"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49008d4",
   "metadata": {},
   "source": [
    "<details><summary><h6>点击查看答案</h6></summary>根据程序，结果257136.43元</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02d9d4",
   "metadata": {},
   "source": [
    "神经网络的力量是有代价的。更复杂的问题需要更大的网络，更大的网络包含更多的参数，而更多的参数需要更多的数据。如果我们试图用太少的数据来拟合一个大的网络，那么这个模型就会过度拟合，做出比更简单的网络更差的预测：如果只有稀少的数据，甚至一个简单的逻辑回归模型也能轻易击败一个大型神经网络。\n",
    "\n",
    "即使我们有足够的数据，更多的参数也意味着更多的计算，在某些时候，我们的计算资源已经耗尽，无法在合理的时间内完成拟合过程。因此，即使是（或特别是）在机器学习中，真的没有免费的午餐。\n",
    "\n",
    "优化神经网络的参数以适应训练数据之所以如此困难，正是我们在第二章中遇到的问题：当激活函数是非线性的时候，优化 \"景观 \"也是高度不规则的，并表现出大量的局部优化，优化器可能会卡住。为了解决这个问题，已经进行了相当多的研究来设计新的和更好的优化算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0d2b9",
   "metadata": {},
   "source": [
    "<h2> 用神经网络预测学生的录取情况 <a id='admission'></a></h2> \n",
    "\n",
    "在这个微型项目中，我们根据三个数据来预测某校研究生院的学生录取（admit）情况。\n",
    "- 研究生考试分数 （gre）\n",
    "- 本科阶段绩点 （gpa）\n",
    "- 本科阶段班级排名 (rank)\n",
    "\n",
    "\n",
    "**加载数据**\n",
    "为了加载数据并使其格式化，我们将使用两个非常有用的软件包，即Pandas和Numpy。你可以在这里阅读相关文档。\n",
    "- https://pandas.pydata.org/pandas-docs/stable/\n",
    "- https://docs.scipy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a867b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入pandas和numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 将csv文件读入pandas DataFrame中，csv文件请从github自行下载，保存在和本文件同一目录下。\n",
    "data = pd.read_csv('student_data.csv')\n",
    "\n",
    "# 打印出我们数据的前10行\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02b7c8",
   "metadata": {},
   "source": [
    "`student.csv`中一共提供了400名学生的数据。**admit**为1表示该生被录取，admit为0表示被拒录。**gre**代表考研成绩，**gpa**是本科绩点，**rank**是本科阶段学生在班级中的排名，按照**4**个等级划分，也就是班级前25%，前50%，后50%和后25%4个分级。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e88ca",
   "metadata": {},
   "source": [
    "#### 绘制数据图\n",
    "\n",
    "首先，让我们为我们的数据做一个图，看看它看起来如何。为了得到一个二维图，我们先不考虑排名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei'] # 指定中文字体\n",
    "\n",
    "# 用来帮助我们绘图的函数\n",
    "def plot_points(data):\n",
    "    X = np.array(data[[\"gre\", \"gpa\"]] )\n",
    "    y = np.array(data[\"admit\"])\n",
    "    admitted = X[np.argwhere(y==1)]\n",
    "    rejected = X[np.argwhere(y==0)]\n",
    "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'red', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'cyan', edgecolor = 'k')\n",
    "    plt.xlabel('考研成绩')\n",
    "    plt.ylabel('绩点')\n",
    "    \n",
    "# 绘制点的图形\n",
    "plot_points(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7450c",
   "metadata": {},
   "source": [
    "粗略看来，考试和绩点分数高的学生通过了，而分数低的学生没有通过，但数据并不像我们希望的那样可以很好地分开。也许把等级排行考虑进去会有帮助？让我们做4张图，每张图对应一个等级。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按分级建立变量\n",
    "data_rank1 = data[data[\"rank\"]==1]\n",
    "data_rank2 = data[data[\"rank\"]==2]\n",
    "data_rank3 = data[data[\"rank\"]==3]\n",
    "data_rank4 = data[data[\"rank\"]==4]\n",
    "\n",
    "# 画图\n",
    "plot_points(data_rank1)\n",
    "plt.title(\"Rank 1\")\n",
    "plt.show()\n",
    "plot_points(data_rank2)\n",
    "plt.title(\"Rank 2\")\n",
    "plt.show()\n",
    "plot_points(data_rank3)\n",
    "plt.title(\"Rank 3\")\n",
    "plt.show()\n",
    "plot_points(data_rank4)\n",
    "plt.title(\"Rank 4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95966a13",
   "metadata": {},
   "source": [
    "这看起来更有希望，因为似乎排名越低，接受率就越高。让我们把等级排行作为我们的输入之一。为了做到这一点，我们应该对它进行独热编码。\n",
    "\n",
    "独热编码（One-Hot Encoding）是一种常用的数据编码技术，用于将离散特征转换为可用于机器学习算法的数值形式。在独热编码中，每个离散特征的每个可能取值都被编码为一个二进制数，其中只有一个二进制位被设置为1，其余位都被设置为0。例如，对于学生的等级排行（一共4级），独热编码将这4个等级分别编码为$[1,0,0,0]、[0,1,0,0]、[0,0,1,0]和[0,0,0,1]$。这样的编码使得机器学习算法可以处理这些离散变量，而不需要对它们进行排序或计算其距离。\n",
    "\n",
    "<h4>练习3 高校录取预测<a id='ex3'></a></h4>\n",
    "<h5>练习3.1 独热编码</h5>\n",
    "\n",
    "使用pandas中的`get_dummies`函数来对数据进行单次编码。\n",
    "\n",
    "提示：要删除一个列，建议使用`one_hot_data`[.drop( )](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e8892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提供代码：利用get_dummies将400名学生的排名，例如第一级，变成独热编码【1，0，0，0】，并分别赋值给4个rank变量\n",
    "one_hot_data = pd.get_dummies(data, columns=['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将one_hot_data中原始的\"rank\"列进行删除\n",
    "pass\n",
    "\n",
    "# 打印我们数据的前10行\n",
    "one_hot_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae855c5",
   "metadata": {},
   "source": [
    "<h5>练习3.2 缩放数据 </h5>\n",
    "\n",
    "下一步是对数据进行缩放。我们注意到，绩点的范围是1.0-4.0，而考试分数的范围大约是200-800（设满分为800分），这要大得多。这意味着我们的数据是偏斜的，这使得神经网络很难处理它。让我们把我们的两个特征放到0-1的范围内，用绩点除以4.0，考试分数除以800。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e60fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制一份我们的数据副本\n",
    "processed_data = one_hot_data[:]\n",
    "\n",
    "# TODO: 缩放列数\n",
    "pass\n",
    "\n",
    "# 打印我们处理后的数据的前10行\n",
    "processed_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c1b719",
   "metadata": {},
   "source": [
    "#### 数据集分为训练集和测试集\n",
    "为了测试我们的算法，我们将把数据分成一个训练集和一个测试集。测试集的大小将是总数据的10%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5836bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.choice(processed_data.index, size=int(len(processed_data)*0.9), replace=False)\n",
    "train_data, test_data = processed_data.iloc[sample], processed_data.drop(sample)\n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(train_data[:10])\n",
    "print(test_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251f5b6",
   "metadata": {},
   "source": [
    "#### 将数据分割成特征和目标（标签）。\n",
    "现在，作为训练前的最后一步，我们将把数据分成特征（X）和目标（Y）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data.drop('admit', axis=1)\n",
    "targets = train_data['admit']\n",
    "features_test = test_data.drop('admit', axis=1)\n",
    "targets_test = test_data['admit']\n",
    "\n",
    "print(features[:10])\n",
    "print(targets[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b143df",
   "metadata": {},
   "source": [
    "#### 训练2层神经网络\n",
    "下面的函数训练了2层神经网络。首先，我们要写一些辅助函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a446330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 激活 (sigmoid) 函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "def error_formula(y, output):\n",
    "    return - y*np.log(output) - (1 - y) * np.log(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810e76d",
   "metadata": {},
   "source": [
    "<h5>练习3.3 误差函数 </h5>\n",
    "写出误差项。记住，这是由方程 $$ (y-\\hat{y}) \\sigma'(x) $$ 给出的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 编写误差项公式\n",
    "def error_term_formula(x, y, output):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f4fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h5>练习3.4 建立模型 </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d53035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络超参数\n",
    "epochs = 1000\n",
    "learnrate = 0.5\n",
    "\n",
    "# 训练功能\n",
    "def train_nn(features, targets, epochs, learnrate):\n",
    "    \n",
    "    # 使用相同的种子以使调试更容易\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "\n",
    "    # 初始化权重\n",
    "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        for x, y in zip(features.values, targets):\n",
    "            # 循环浏览所有记录，x是输入，y是目标\n",
    "\n",
    "            # 激活输出单元\n",
    "            # 注意我们在这里将输入和权重相乘 \n",
    "            # 而不是将h作为一个单独的变量来存储 \n",
    "            output = sigmoid(np.dot(x, weights))\n",
    "\n",
    "            # 误差，目标值减去网络的输出值\n",
    "            error = error_formula(y, output)\n",
    "\n",
    "            # 误差项\n",
    "            error_term = error_term_formula(x, y, output)\n",
    "\n",
    "            # 梯度下降步骤，误差乘以梯度乘以输入量\n",
    "            del_w += error_term * x\n",
    "\n",
    "        # 在这里更新权重。学习率乘以 \n",
    "        # 权重的变化，除以要取平均值的记录数\n",
    "        weights += learnrate * del_w / n_records\n",
    "\n",
    "        # 打印出训练集上的平均平方误差\n",
    "        if e % (epochs / 10) == 0:\n",
    "            out = sigmoid(np.dot(features, weights) )\n",
    "            loss = np.mean((out - targets) ** 2)\n",
    "            print(\"Epoch:\", e)\n",
    "            if last_loss和last_loss < loss:\n",
    "                print(\"Train loss: \", loss, \" WARNING - Loss Increasing\")\n",
    "            else:\n",
    "                print(\"Train loss: \" , loss)\n",
    "            last_loss = loss\n",
    "            print(\"=========\")\n",
    "    print(\"训练结束！\")\n",
    "    return weights\n",
    "    \n",
    "weights = train_nn(features, targets, epochs, learnrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7392afd",
   "metadata": {},
   "source": [
    "<h5> 练习3.5 计算准确率 </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试数据上计算出准确性\n",
    "test_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = test_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恭喜你完成实验六的练习"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
